# Pipeline de CNN para ClasificaciÃ³n de ImÃ¡genes CIFAR-10

Proyecto de clasificaciÃ³n de imÃ¡genes utilizando redes neuronales convolucionales (CNN) sobre el dataset CIFAR-10 y evaluaciÃ³n en CIFAR-10.1.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un pipeline completo de entrenamiento, validaciÃ³n y evaluaciÃ³n de modelos CNN para clasificaciÃ³n de imÃ¡genes. Incluye:

- 4 arquitecturas de red diferentes
- Pipeline de entrenamiento con early stopping
- Sistema de checkpoints automÃ¡tico
- EvaluaciÃ³n en CIFAR-10.1
- Visualizaciones profesionales de mÃ©tricas

## ğŸ—ï¸ Arquitecturas Disponibles

### 1. **BaseModel**
Modelo baseline con arquitectura fully connected simple.
- 2 capas densas (3072 â†’ 512 â†’ 10)
- ActivaciÃ³n Tanh
- ~1.6M parÃ¡metros
- Accuracy esperado: ~45-50%

### 2. **SimpleCNN**
CNN bÃ¡sica con 3 bloques convolucionales.
- 3 bloques: Conv â†’ ReLU â†’ MaxPool
- Canales: 3 â†’ 32 â†’ 64 â†’ 128
- 2 capas fully connected
- Dropout (0.5) para regularizaciÃ³n
- ~850K parÃ¡metros
- Accuracy esperado: ~65-70%

### 3. **ImprovedCNN** â­ (Recomendada)
CNN mejorada con Batch Normalization.
- 5 bloques convolucionales con BatchNorm
- Canales: 3 â†’ 64 â†’ 128 â†’ 256 â†’ 256 â†’ 512
- Dropout entre capas
- BatchNorm en capas convolucionales y fully connected
- ~6.5M parÃ¡metros
- Accuracy esperado: ~75-85%

### 4. **ResNetCIFAR**
Arquitectura tipo ResNet con skip connections.
- Bloques residuales con shortcuts
- 3 grupos de bloques (64, 128, 256 canales)
- Global Average Pooling
- BatchNorm en todas las capas convolucionales
- ~300K parÃ¡metros
- Accuracy esperado: ~80-88%

## ğŸ“¦ InstalaciÃ³n

### Requisitos
- Python 3.8+
- pip o conda

### Instalar dependencias

```bash
# OpciÃ³n 1: Usando pip
pip install -r requirements.txt

# OpciÃ³n 2: Crear entorno virtual (recomendado)
python -m venv .venv
source .venv/bin/activate  # En Linux/Mac
# .\.venv\Scripts\Activate.ps1  # En Windows
pip install -r requirements.txt
```

### Dependencias principales
- PyTorch >= 2.0.0
- torchvision >= 0.15.0
- numpy >= 1.24.0
- matplotlib >= 3.7.0
- seaborn >= 0.12.0
- scikit-learn >= 1.3.0
- torchview >= 0.2.6 (opcional, para visualizaciÃ³n de arquitecturas)

## ğŸš€ EjecuciÃ³n

### Estructura del proyecto

```
src/
â”œâ”€â”€ main.py                 # Script principal de ejecuciÃ³n
â”œâ”€â”€ arqui_cnn.py           # DefiniciÃ³n de arquitecturas CNN
â”œâ”€â”€ train_pipeline.py      # Pipeline de entrenamiento
â”œâ”€â”€ load.py                # Carga de datasets
â”œâ”€â”€ pre_processed.py       # Preprocesamiento y transformaciones
â”œâ”€â”€ test.py                # EvaluaciÃ³n en CIFAR-10.1
â”œâ”€â”€ auxiliares.py          # Funciones auxiliares
â”œâ”€â”€ models.py              # Enumeradores y configuraciones
â”œâ”€â”€ requirements.txt       # Dependencias
â””â”€â”€ pyproject.toml         # ConfiguraciÃ³n de herramientas
```

### Ejecutar el proyecto completo

```bash
# Activar el entorno virtual (si se creÃ³)
source .venv/bin/activate  # Linux/Mac
# .\.venv\Scripts\Activate.ps1  # Windows (PowerShell)

# Ejecutar el pipeline completo
python main.py
```

### ConfiguraciÃ³n de hiperparÃ¡metros

Edita la configuraciÃ³n en `main.py` (lÃ­neas 35-43):

```python
config = {
    'lr': 0.001,              # Learning rate
    'epochs': 100,            # NÃºmero de Ã©pocas
    'batch_size': 64,         # TamaÃ±o del batch
    'patience': 10,           # Early stopping patience
    'checkpoint_dir': 'models/',  # Directorio de checkpoints
    'optimizer': 'AdamW',     # Optimizador: 'SGD', 'Adam', 'AdamW', 'RMSProp'
}
```

### Seleccionar arquitectura

En `main.py` (lÃ­neas 78-82), descomenta el modelo deseado:

```python
# model = BaseModel()         # Baseline simple
# model = SimpleCNN()         # CNN bÃ¡sica
model = ImprovedCNN()         # CNN mejorada (por defecto)
# model = ResNetCIFAR()       # ResNet adaptado
```

## ğŸ“Š Resultados y Checkpoints

Durante el entrenamiento, se generan automÃ¡ticamente:

### Checkpoints
- `models/best_model.pth` - Mejor modelo segÃºn accuracy de validaciÃ³n
- `models/last_checkpoint.pth` - Checkpoint cada 5 Ã©pocas
- `models/interrupted_checkpoint.pth` - Si se interrumpe con Ctrl+C

### Visualizaciones
- Curvas de entrenamiento (Loss y Accuracy)
- Matriz de confusiÃ³n en CIFAR-10.1
- Ejemplos de predicciones correctas/incorrectas
- Medida de overfitting

## ğŸ”„ Reanudar Entrenamiento

Si el entrenamiento se interrumpe, puedes reanudarlo:

```python
# En main.py, descomenta la lÃ­nea:
pipeline.resume_training('interrupted_checkpoint.pth', train_dataloader, validation_dataloader)
```

## ğŸ¯ EvaluaciÃ³n

El pipeline incluye evaluaciÃ³n automÃ¡tica en CIFAR-10.1:
- Accuracy global
- Accuracy por clase
- Matriz de confusiÃ³n
- VisualizaciÃ³n de predicciones

## ğŸ”§ Funciones Auxiliares

### Comparar arquitecturas
```python
from auxiliares import compare_models
compare_models()  # Muestra parÃ¡metros de todas las arquitecturas
```

### Detectar hardware disponible
```python
from auxiliares import que_fierro_tengo
que_fierro_tengo()  # Muestra GPU/CPU disponible
```

### Visualizar arquitectura
```python
from auxiliares import draw_model
from arqui_cnn import ImprovedCNN

model = ImprovedCNN()
draw_model(model)  # Requiere torchview instalado
```

## ğŸ“ˆ Mejores PrÃ¡cticas

1. **Data Augmentation**: El preprocesamiento incluye:
   - Random horizontal flip
   - Random resized crop
   - NormalizaciÃ³n con media y std de CIFAR-10

2. **RegularizaciÃ³n**:
   - Dropout (0.5)
   - Batch Normalization
   - Label smoothing (0.05)
   - Early stopping

3. **OptimizaciÃ³n**:
   - Soporte para mÃºltiples optimizadores
   - DetecciÃ³n automÃ¡tica de GPU (CUDA/MPS)
   - Checkpoints automÃ¡ticos

## ğŸ› Troubleshooting

### Error: "No module named 'torch'"
```bash
pip install torch torchvision
```

### Error: "CUDA out of memory"
Reduce el batch_size en la configuraciÃ³n:
```python
config['batch_size'] = 32  # o 16
```

### Warning: "torchview no estÃ¡ instalado"
```bash
pip install torchview
```
Esto solo afecta la visualizaciÃ³n de arquitecturas, el entrenamiento funcionarÃ¡ normalmente.

## ğŸ“š Referencias

- **CIFAR-10**: https://www.cs.toronto.edu/~kriz/cifar.html
- **CIFAR-10.1**: https://github.com/modestyachts/CIFAR-10.1
- **PyTorch**: https://pytorch.org/

## ğŸ‘¥ Autores

Proyecto desarrollado para la materia de VisiÃ³n por Computadora - UBA

## ğŸ’¾ Hacer Commits

El proyecto usa pre-commit hooks para validar cÃ³digo:

```bash
# Agregar todos los cambios
git add -A

# Hacer commit (usa --no-verify si pre-commit falla)
git commit -m "Tu mensaje"

# Si pre-commit modifica archivos, agregarlos y commitear nuevamente
git add -A
git commit -m "Tu mensaje"
```

**Nota**: Si pre-commit entra en conflicto, usa `git commit --no-verify` para saltarlo.

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico.
